!pip install pyswarm

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
from pyswarm import pso

from google.colab import drive
drive.mount('/content/drive')

train_path = '/content/drive/MyDrive/miniproject_5thsem/Training'
test_path = '/content/drive/MyDrive/miniproject_5thsem/Testing'

def load_data(data_path):
    data = []
    labels = []
    class_names = sorted(os.listdir(data_path))
    for class_index, class_name in enumerate(class_names):
        class_dir = os.path.join(data_path, class_name)
        for img_name in os.listdir(class_dir):
            img_path = os.path.join(class_dir, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_COLOR)
            img = cv2.resize(img, (64, 64))
            data.append(img)
            labels.append(class_index)
    return np.array(data), np.array(labels)

X_train, y_train = load_data(train_path)
X_test, y_test = load_data(test_path)

# Normalize pixel values
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Convert labels to categorical
num_classes = len(np.unique(y_train))
y_train = to_categorical(y_train, num_classes=num_classes)
y_test = to_categorical(y_test, num_classes=num_classes)

def create_cnn_model(learning_rate, num_filters, dense_units, dropout_rate):
    model = Sequential()
    model.add(Conv2D(int(num_filters), (3, 3), activation='relu', input_shape=(64, 64, 3)))
    model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(int(dense_units), activation='relu'))
    model.add(Dropout(dropout_rate))
    model.add(Dense(num_classes, activation='softmax'))
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def evaluate_model(params):
    learning_rate, num_filters, dense_units, dropout_rate, batch_size = params
    model = create_cnn_model(learning_rate, num_filters, dense_units, dropout_rate)
    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
    history = model.fit(X_train, y_train, epochs=10, batch_size=int(batch_size), validation_split=0.2, callbacks=[early_stopping], verbose=1)
    y_pred = model.predict(X_test)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)
    accuracy = accuracy_score(y_true_classes, y_pred_classes)
    return -accuracy  # Return negative accuracy for minimization

# PSO bounds definition
bounds = [
    (1e-5, 1e-2),  # learning_rate
    (16, 64),      # num_filters
    (64, 256),     # dense_units
    (0.1, 0.5),    # dropout_rate
    (16, 64)       # batch_size
]

# Run PSO
best_params, best_score = pso(evaluate_model, [b[0] for b in bounds], [b[1] for b in bounds], swarmsize=10, maxiter=10)

# Extract and print best hyperparameters found by PSO
print('Best hyperparameters found by PSO:')
print('Learning Rate:', best_params[0])
print('Number of Filters:', best_params[1])
print('Dense Units:', best_params[2])
print('Dropout Rate:', best_params[3])
print('Batch Size:', best_params[4])

final_model = create_cnn_model(best_params[0], best_params[1], best_params[2], best_params[3])
final_model.fit(X_train, y_train, epochs=10, batch_size=int(best_params[4]), validation_split=0.2)
final_loss, final_accuracy = final_model.evaluate(X_test, y_test)
print('Final test accuracy:', final_accuracy)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
y_true_classes = [0, 1, 2, 3, 0, 1, 2, 3]  # Example true labels
y_pred_classes = [0, 1, 2, 3, 1, 0, 2, 3]  # Example predicted labels

class_names = ['glioma', 'meningioma', 'no tumor', 'pituitary']

# Compute the confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)

# Plot the confusion matrix heatmap
fig, ax = plt.subplots(1, 1, figsize=(14, 7))
sns.heatmap(cm, ax=ax, xticklabels=class_names, yticklabels=class_names, annot=True,
            cmap='Greens', alpha=0.7, linewidths=2, linecolor='grey')

# Add title
fig.text(s='Heatmap of the Confusion Matrix', size=18, fontweight='bold',
         fontname='monospace', color='black', y=0.92, x=0.28, alpha=0.8)

plt.show()

import cv2
import numpy as np
from keras.models import load_model

# Load your trained model


# Define class names according to your model's output
class_names = ['glioma', 'meningioma', 'no tumor', 'pituitary']

def preprocess_image(image_path):
    # Load the image using OpenCV
    img = cv2.imread(image_path)
    # Resize the image to match the input size of your model
    img = cv2.resize(img, (64, 64))  # Adjust size according to your model's input shape
    # Preprocess the image: normalize pixel values
    img = img.astype('float32') / 255.0
    # Expand dimensions to match the batch size used by your model
    img = np.expand_dims(img, axis=0)
    return img

def predict_tumor_type(image_path):
    # Preprocess the image
    img = preprocess_image(image_path)
    # Predict tumor type using your model
    predictions = final_model.predict(img)
    # Get the predicted class index
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    # Map the index to the class name
    predicted_class = class_names[predicted_class_index]
    return predicted_class

# Example usage:
image_path = '/content/drive/MyDrive/miniproject_5thsem/Testing/glioma/Te-glTr_0000.jpg'  # Replace with the path to your image
predicted_tumor_type = predict_tumor_type(image_path)
print('Predicted tumor type:', predicted_tumor_type)

import cv2
import numpy as np
from keras.models import load_model

# Load your trained model


# Define class names according to your model's output
class_names = ['glioma', 'meningioma', 'no tumor', 'pituitary']

def preprocess_image(image_path):
    # Load the image using OpenCV
    img = cv2.imread(image_path)
    # Resize the image to match the input size of your model
    img = cv2.resize(img, (64, 64))  # Adjust size according to your model's input shape
    # Preprocess the image: normalize pixel values
    img = img.astype('float32') / 255.0
    # Expand dimensions to match the batch size used by your model
    img = np.expand_dims(img, axis=0)
    return img

def predict_tumor_type(image_path):
    # Preprocess the image
    img = preprocess_image(image_path)
    # Predict tumor type using your model
    predictions = final_model.predict(img)
    # Get the predicted class index
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    # Map the index to the class name
    predicted_class = class_names[predicted_class_index]
    return predicted_class

# Example usage:
image_path = '/content/drive/MyDrive/miniproject_5thsem/Testing/meningioma/Te-meTr_0004.jpg'  # Replace with the path to your image
predicted_tumor_type = predict_tumor_type(image_path)
print('Predicted tumor type:', predicted_tumor_type)

import cv2
import numpy as np
from keras.models import load_model

# Load your trained model


# Define class names according to your model's output
class_names = ['glioma', 'meningioma', 'no tumor', 'pituitary']

def preprocess_image(image_path):
    # Load the image using OpenCV
    img = cv2.imread(image_path)
    # Resize the image to match the input size of your model
    img = cv2.resize(img, (64, 64))  # Adjust size according to your model's input shape
    # Preprocess the image: normalize pixel values
    img = img.astype('float32') / 255.0
    # Expand dimensions to match the batch size used by your model
    img = np.expand_dims(img, axis=0)
    return img

def predict_tumor_type(image_path):
    # Preprocess the image
    img = preprocess_image(image_path)
    # Predict tumor type using your model
    predictions = final_model.predict(img)
    # Get the predicted class index
    predicted_class_index = np.argmax(predictions, axis=1)[0]
    # Map the index to the class name
    predicted_class = class_names[predicted_class_index]
    return predicted_class


image_path = '/content/drive/MyDrive/miniproject_5thsem/Testing/notumor/Te-noTr_0008.jpg'
predicted_tumor_type = predict_tumor_type(image_path)
print('Predicted tumor type:', predicted_tumor_type)

